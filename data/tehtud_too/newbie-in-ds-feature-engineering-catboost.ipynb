{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":57891,"databundleVersionId":7056235,"sourceType":"competition"}],"dockerImageVersionId":30587,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Optvier - Trading at close\n\n## Introduction\n\nFirst we should thanks optiver for holding this competition for Data science/Quant community. The aim of this notebook is to *predict* the closing price of stocks. The reason of predicting the closing prices is that there is an evidence of large amount of trades are made in last ten minutes before the close of the market. Hence, closing prices can be served as an indicator for traders to evaluate the stocks. \n\n## Work Flow of this notebook \nThere are several thing I would like to achieve in this notebook. The first is a simple elementart data analysis (EDA) of the stock data. There are some features which deserve an attention such as the `imbalance volume`, `ask/bid size`, and `axsk/bid price`, which are the essential features to make an `order book`. Secondly, based on the EDA, the next step is feature engineering, buyt I would say `feature reverse-engineering`. There are lots of notebook availables in the competitions and it's good to `reverse engineer` the mindset of building those features and then try to build by our own. Once features engineering is done, we come to the model selection and training. I have to ideas in my mind: `transformer AE kind RNN` or `XGBoost`. They are the paradigms of time-series forecasting but I prefer XGBoost due to its simplicity. Finally, we will use the test set to make prediction and submit to the organization. To sum up, our work flow is: \n1. Data Preprocessing and Elementary Data Analysis\n2. Features Engineering \n3. Model Selection [`XGBoost`]\n4. Prediction and Submission\n","metadata":{}},{"cell_type":"code","source":"# Data Analytic Tools\nimport matplotlib.pyplot as plt \nimport pandas as pd\nimport seaborn as sns \nimport plotly.express as px\nimport plotly.graph_objects as go\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n\n# Computing Tools \nimport lightgbm as lgb \nimport xgboost as xgb \nimport catboost as cbt \nimport numpy as np \nimport joblib \nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2023-12-08T17:14:37.719606Z","iopub.execute_input":"2023-12-08T17:14:37.719946Z","iopub.status.idle":"2023-12-08T17:14:37.739126Z","shell.execute_reply.started":"2023-12-08T17:14:37.71992Z","shell.execute_reply":"2023-12-08T17:14:37.737489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Section 1: Data Preprocessing and Elementary Data Analysis\n\n## Dataset Introduction \n\n- `stock_id` - A unique identifier for the stock. Not all stock IDs exist in every time bucket.\n- `date_id` - A unique identifier for the date. Date IDs are sequential & consistent across all stocks.\n- `imbalance_size` - The amount unmatched at the current reference price (in USD).\n- `imbalance_buy_sell_flag` - An indicator reflecting the direction of auction imbalance.\n    * buy-side imbalance; 1\n    * sell-side imbalance; -1\n    * no imbalance; 0\n- `reference_price` - The price at which paired shares are maximized, the imbalance is minimized and the distance from the bid-ask midpoint is minimized, in that order. Can also be thought of as being equal to the near price bounded between the best bid and ask price.\n- `matched_size` - The amount that can be matched at the current reference price (in USD).\n- `far_price` - The crossing price that will maximize the number of shares matched based on auction - - - interest only. This calculation excludes continuous market orders.\n- `near_price` - The crossing price that will maximize the number of shares matched based auction and continuous market orders.\n- `[bid/ask]_price` - Price of the most competitive buy/sell level in the non-auction book.\n- `[bid/ask]_size` - The dollar notional amount on the most competitive buy/sell level in the non-auction book.\n- `wap` - The weighted average price in the non-auction book.\n$$\n\\frac{\\text{Bid Price } \\times \\text{Ask Size}  +  \\text{Ask Price } \\times \\text{Bid Size} }{ \\text{Bid Size + Ask Size}}\n$$\n- `seconds_in_bucket` - The number of seconds elapsed since the beginning of the day's closing auction, always starting from 0.\n- `target` - The 60 second future move in the wap of the stock, less the 60 second future move of the synthetic index. Only provided for the train set.\n    * The synthetic index is a custom weighted index of Nasdaq-listed stocks constructed by Optiver for this competition.\n    * The unit of the target is basis points, which is a common unit of measurement in financial markets. A 1 basis point price move is equivalent to a 0.01% price move.\n    * Where t is the time at the current observation, we can define the target:\n        $$\n        \\text{Target} =  \\Big( \\frac{\\text{Stock WAP}_{t + 60}}{\\text{Stock WAP}_{t}} - \\frac{\\text{Index WAP}_{t+60} }{ \\text{Index WAP}_t} \\Big) * 10000\n        $$\n        All size related columns are in USD terms.\n\n\nReferences:\n- [High Frequency Trading II: Limit Order Book](https://www.quantstart.com/articles/high-frequency-trading-ii-limit-order-book/)\n","metadata":{}},{"cell_type":"code","source":"# load the train.csv file using pandas build in function \ntrain = pd.read_csv('/kaggle/input/optiver-trading-at-the-close/train.csv')\n\n# Print the first five value row of the dataset \ntrain.head()\n\n# Print out the nan/ null values counts in each features\ntrain.isnull().sum()\n\n# Drop the nan/null values in the target since it would help for the inference \ntrian = train.dropna(subset=['target'])\n\n# Drop the index inplace \ntrain.reset_index(drop=True, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-08T17:14:37.740838Z","iopub.execute_input":"2023-12-08T17:14:37.741207Z","iopub.status.idle":"2023-12-08T17:14:45.199968Z","shell.execute_reply.started":"2023-12-08T17:14:37.741142Z","shell.execute_reply":"2023-12-08T17:14:45.198404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1.1 Data Preprocessing with Numba/JIT\n\nIn this subsession, we will preprocess the data and try to optimize the memory usages. One trick is to convert the data type in order to reduce the memory. ","metadata":{}},{"cell_type":"markdown","source":"# 1.2 Elemetary Data Analysis\n\nIn this subsession, we are going to inverstigate the the relation between each prices and sizes. Instead of tracking all stocks at all time, we examine the `stock[id==0]` and `date_id <= 5` as the exmaple notebook of Optiver. The reason of choosing `5 days` is that previously I picked `date_id ==0` but I could not see any negative imbalance. \n\n### Major Findings????\n- [Iceberg Order? (short review in Chinese)](https://www.zhihu.com/question/23667442): In some moments, either the bid/ask sizes are several orders higher.\n\n\n\n\nReference Notebooks:\n- [Introduction and Explore Data Analysis](https://www.kaggle.com/code/chiangken/introduction-and-explore-data-analysis)\n- [Optiver 2023 | EDA | PyTorch: LSTM-Attention Model](https://www.kaggle.com/code/aniketkolte04/optiver-2023-eda-pytorch-lstm-attention-model)\n- [Optiver Trading at Close Intro.](https://www.kaggle.com/code/tomforbes/optiver-trading-at-the-close-introduction)","metadata":{}},{"cell_type":"code","source":"# define the df of stock00: \n\nstock00 = train.query('stock_id ==0 & date_id <5')\nstock00","metadata":{"execution":{"iopub.status.busy":"2023-12-08T17:14:45.202309Z","iopub.execute_input":"2023-12-08T17:14:45.202638Z","iopub.status.idle":"2023-12-08T17:14:45.24739Z","shell.execute_reply.started":"2023-12-08T17:14:45.202611Z","shell.execute_reply":"2023-12-08T17:14:45.246222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# PLot the Prices changes of stock 0 at date 0 \nfig = go.Figure()\n\nfig.add_trace(\n    go.Scatter(x = stock00['time_id'], \n            y = stock00['ask_price'], \n            name = 'ask price',\n            line = dict(color = 'red')))\n\nfig.add_trace(\n    go.Scatter(x = stock00['time_id'], \n            y = stock00['bid_price'], \n            name = 'bid price',\n            line = dict(color = 'green')))\n\nfig.add_trace(\n    go.Scatter(x = stock00['time_id'], \n            y = stock00['wap'], \n            name = 'WAP',\n            line = dict(color = 'orange')))\n\nfig.update_layout(title = \"Overview for Ask/Bid Price and WAP\") ","metadata":{"execution":{"iopub.status.busy":"2023-12-08T17:14:45.249336Z","iopub.execute_input":"2023-12-08T17:14:45.250082Z","iopub.status.idle":"2023-12-08T17:14:45.267255Z","shell.execute_reply.started":"2023-12-08T17:14:45.25004Z","shell.execute_reply":"2023-12-08T17:14:45.265289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Examine the volume changes \n# PLot the Prices changes of stock 0 at date 0 \nfig = go.Figure()\n\nfig.add_trace(\n    go.Scatter(x = stock00['time_id'], \n            y = stock00['ask_size'],  \n            name = 'ask size',\n            line = dict(color = 'red')))\n\nfig.add_trace(\n    go.Scatter(x = stock00['time_id'], \n            y = stock00['bid_size'], \n            name = 'bid size',\n            line = dict(color = 'green')))\n\nfig.update_layout(title = \"Overview for Normalized Ask/Bid Sizes Comparison for 5 days (WHy large ask Size)\")","metadata":{"execution":{"iopub.status.busy":"2023-12-08T17:14:45.270304Z","iopub.execute_input":"2023-12-08T17:14:45.270728Z","iopub.status.idle":"2023-12-08T17:14:45.289258Z","shell.execute_reply.started":"2023-12-08T17:14:45.270697Z","shell.execute_reply":"2023-12-08T17:14:45.287982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Examine the volume changes \n# PLot the Prices changes of stock 0 at date 0 \nfig = go.Figure()\n\nfig.add_trace(\n    go.Scatter(x = stock00['time_id'], \n            y = (stock00['ask_size'] - stock00['ask_size'].min()) / (stock00['ask_size'].max() - stock00['ask_size'].min()), \n            name = 'ask size',\n            line = dict(color = 'red')))\n\nfig.add_trace(\n    go.Scatter(x = stock00['time_id'], \n            y = (stock00['bid_size'] - stock00['bid_size'].min()) / (stock00['bid_size'].max() - stock00['bid_size'].min()), \n            name = 'bid size',\n            line = dict(color = 'green')))\n\n\nfig.add_trace(\n    go.Scatter(x = stock00['time_id'], \n            y = (stock00['wap'] - stock00['wap'].min()) / (stock00['wap'].max() - stock00['wap'].min()), \n            name = 'WAP',\n            line = dict(color = 'orange')))\n\n\n\nfig.update_layout(title = \"Overview for Normalized Ask/Bid Sizes and WAP for 5 days\")\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-08T17:14:45.291084Z","iopub.execute_input":"2023-12-08T17:14:45.2915Z","iopub.status.idle":"2023-12-08T17:14:45.310866Z","shell.execute_reply.started":"2023-12-08T17:14:45.291469Z","shell.execute_reply":"2023-12-08T17:14:45.31015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Examine the volume changes \n# PLot the Prices changes of stock 0 at date 0 \n\ntotal_size = stock00.eval('ask_size + bid_size').values\n\nfig = go.Figure()\n\nfig.add_trace(\n    go.Scatter(x = stock00['time_id'], \n            y = (total_size - total_size.min()) / (total_size.max() - total_size.min()), \n            name = 'total size',\n            line = dict(color = 'blue')))\n\n\n\nfig.add_trace(\n    go.Scatter(x = stock00['time_id'], \n            y = (stock00['wap'] - stock00['wap'].min()) / (stock00['wap'].max() - stock00['wap'].min()), \n            name = 'WAP',\n            line = dict(color = 'orange')))\n\nfig.update_layout(title = \"Overview for Normalized Total Sizes and WAP for 5 days\") ","metadata":{"execution":{"iopub.status.busy":"2023-12-08T17:14:45.311892Z","iopub.execute_input":"2023-12-08T17:14:45.312173Z","iopub.status.idle":"2023-12-08T17:14:45.337524Z","shell.execute_reply.started":"2023-12-08T17:14:45.312127Z","shell.execute_reply":"2023-12-08T17:14:45.336342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_size = stock00.eval('ask_size + bid_size').values\n\nfig = go.Figure()\n\nfig.add_trace(\n    go.Scatter(x = stock00['time_id'], \n            y = (stock00['target'] - stock00['target'].min()) \\\n               / (stock00['target'].max() - stock00['target'].min()) ,\n            name = 'total size',\n            line = dict(color = 'blue')))\n\n\n\nfig.add_trace(\n    go.Scatter(x = stock00['time_id'], \n            y = (stock00['wap'] - stock00['wap'].min()) / (stock00['wap'].max() - stock00['wap'].min()), \n            name = 'WAP',\n            line = dict(color = 'orange')))\n\nfig.update_layout(title = \"Overview for Normalized Target and WAP for 5 days\") ","metadata":{"execution":{"iopub.status.busy":"2023-12-08T17:14:45.338739Z","iopub.execute_input":"2023-12-08T17:14:45.339107Z","iopub.status.idle":"2023-12-08T17:14:45.359275Z","shell.execute_reply.started":"2023-12-08T17:14:45.339078Z","shell.execute_reply":"2023-12-08T17:14:45.358481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Section 2: Feature Engineering. \n\nSince there are no right answers of which features should be built. Therefore, based on some intuition I will make several features for example. Before going to the detail, lets see an equation which is the Geometric Brownian motion in differential form\n\n$$\ndS(t) = \\mu S(t) dt + \\sigma S(t) dW(t) \\Leftrightarrow  S(t) = S_0 \\exp \\Big( (\\mu - \\frac{\\sigma^2}{2}) t + \\sigma W_t \\Big ) \n$$\n\nwhere $\\mu, \\sigma$, and $W(t)$ is the drift, volatility, and the standard Brownian motion. From CgatGPT, it gives us more concrete explanation on these variables:\n\n- $\\mu$ represents the drift component, which is the average or expected growth rate.\n- $\\sigma$ represents the volatility component, which measures the standard deviation of the variable's returns.\n- $S(t)$ represents the value of the variable at time $t$\n\nFor the Brownian motion $W(t)$, we can think of it as an Binomial model where at each time $t$, we either winning or losing 1 dolalr. Therefore, we can write down the discrete form of Brownian motion $W(t)$: \n\n$$\nW = X_1 + X_2 + \\cdots + X_n ,~ X \\in \\{-1 ,1 \\}  \\sim  Bern(p) \n$$\n\nBy linearity of expectation and CLT, we can show that $W \\sim \\mathcal{N}(0, \\text{some mean}) $, where $\\mathbb{E} W = 0 $ for $p = 0.5$ ( equal chance of winning or losing)\n","metadata":{}},{"cell_type":"markdown","source":"# Section 2.X Create Featured Dataset \n\n\nReference Notebooks:\n- [ðŸ¥‡ðŸ¥‡baseline lgb, xgb and catboostðŸ¥‡ðŸ¥‡](https://www.kaggle.com/code/yuanzhezhou/baseline-lgb-xgb-and-catboost)\n- [Explained singel modelâš¡Optiver ](https://www.kaggle.com/code/zulqarnainali/explained-singel-model-optiver)","metadata":{}},{"cell_type":"code","source":"from numba import njit, prange\n\n# ðŸ“Š Function to compute triplet imbalance in parallel using Numba\ndef generate_features(df: pd.DataFrame) -> pd.DataFrame:\n    features = ['seconds_in_bucket', 'imbalance_buy_sell_flag',\n               'imbalance_size', 'matched_size', 'bid_size', 'ask_size',\n                'reference_price','far_price', 'near_price', 'ask_price', 'bid_price', 'wap',\n                'imb_s1', 'imb_s2'\n               ]\n    \n    df['imb_s1'] = df.eval('(bid_size-ask_size)/(bid_size+ask_size)')\n    df['imb_s2'] = df.eval('(imbalance_size-matched_size)/(matched_size+imbalance_size)')\n    \n    prices = ['reference_price','far_price', 'near_price', 'ask_price', 'bid_price', 'wap']\n    \n    # iceburg ask \n#     df['iceburg_ask'] = df['ask_size']\n#     for i in range(len(df)):\n#         if df['bid_size'][i] > 10 * df['ask_size'][i]: \n#             df['iceburg_ask'][i + 10] += df['bid_size'][i]\n#     features.append('iceburg_ask')\n            \n#     # iceburg bid \n#     df['iceburg_bid'] = df['bid_size']\n#     for i in range(len(df['ask_size'])):\n#         if df['ask_size'][i] > 10 * df['bid_size'][i]: \n#             df['iceburg_bid'][i + 10] += df['ask_size'][i]\n#     features.append(f'iceburg_bid')\n    \n    return df[features]\n    ","metadata":{"execution":{"iopub.status.busy":"2023-12-08T17:14:45.360351Z","iopub.execute_input":"2023-12-08T17:14:45.360744Z","iopub.status.idle":"2023-12-08T17:14:45.372439Z","shell.execute_reply.started":"2023-12-08T17:14:45.360719Z","shell.execute_reply":"2023-12-08T17:14:45.371008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Section 3: Model Selection CatBoost","metadata":{}},{"cell_type":"code","source":"# TRAINING = True\n# if TRAINING:\n# #    df_train = pd.read_csv('/kaggle/input/optiver-trading-at-the-close/train.csv')\n#    df_ = generate_features(train)","metadata":{"execution":{"iopub.status.busy":"2023-12-08T17:14:45.373416Z","iopub.execute_input":"2023-12-08T17:14:45.374599Z","iopub.status.idle":"2023-12-08T17:14:45.383973Z","shell.execute_reply.started":"2023-12-08T17:14:45.374565Z","shell.execute_reply":"2023-12-08T17:14:45.382843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAINING = True\nif TRAINING:\n   df_ = generate_features(train)","metadata":{"execution":{"iopub.status.busy":"2023-12-08T17:14:45.386242Z","iopub.execute_input":"2023-12-08T17:14:45.38734Z","iopub.status.idle":"2023-12-08T17:14:45.5519Z","shell.execute_reply.started":"2023-12-08T17:14:45.387295Z","shell.execute_reply":"2023-12-08T17:14:45.551231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path ='/kaggle/input/RKCP0219'\nos.makedirs('models', exist_ok=True)\n\nN_fold = 5\n\nif TRAINING:\n    X = df_.values\n    Y = train['target'].values\n\n    X = X[np.isfinite(Y)]\n    Y = Y[np.isfinite(Y)]\n\n    index = np.arange(len(X))","metadata":{"execution":{"iopub.status.busy":"2023-12-08T17:14:45.552777Z","iopub.execute_input":"2023-12-08T17:14:45.554037Z","iopub.status.idle":"2023-12-08T17:14:45.834965Z","shell.execute_reply.started":"2023-12-08T17:14:45.553989Z","shell.execute_reply":"2023-12-08T17:14:45.834254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = []\n\ndef train(model_dict, modelname='lgb'):\n    if TRAINING:\n        model = model_dict[modelname]\n        model.fit(X[index%N_fold!=i], Y[index%N_fold!=i], \n                    eval_set=[(X[index%N_fold==i], Y[index%N_fold==i])], \n                    verbose=10, \n                    early_stopping_rounds=100\n                    )\n        models.append(model)\n        joblib.dump(model, './models/{modelname}_{i}.model')\n    else:\n        models.append(joblib.load(f'{model_path}/{modelname}_{i}.model'))\n    return \n\nmodel_dict = {\n    'cbt': cbt.CatBoostRegressor(objective='MAE', iterations=10),\n\n}\n\nfor i in range(N_fold):\n    train(model_dict, 'cbt')","metadata":{"execution":{"iopub.status.busy":"2023-12-08T17:14:45.836021Z","iopub.execute_input":"2023-12-08T17:14:45.836524Z","iopub.status.idle":"2023-12-08T17:17:42.905755Z","shell.execute_reply.started":"2023-12-08T17:14:45.8365Z","shell.execute_reply":"2023-12-08T17:17:42.904959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import optiver2023\nenv = optiver2023.make_env()\niter_test = env.iter_test()","metadata":{"execution":{"iopub.status.busy":"2023-12-08T17:17:42.906743Z","iopub.execute_input":"2023-12-08T17:17:42.907195Z","iopub.status.idle":"2023-12-08T17:17:42.934829Z","shell.execute_reply.started":"2023-12-08T17:17:42.907144Z","shell.execute_reply":"2023-12-08T17:17:42.933657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"counter = 0\nfor (test, revealed_targets, sample_prediction) in iter_test:\n    feat = generate_features(test)\n    \n    sample_prediction['target'] = np.mean([model.predict(feat) for model in models], 0)\n    env.predict(sample_prediction)\n    counter += 1","metadata":{"execution":{"iopub.status.busy":"2023-12-08T17:17:42.936386Z","iopub.execute_input":"2023-12-08T17:17:42.936734Z","iopub.status.idle":"2023-12-08T17:17:45.21505Z","shell.execute_reply.started":"2023-12-08T17:17:42.936702Z","shell.execute_reply":"2023-12-08T17:17:45.213513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}